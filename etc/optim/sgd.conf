#
# example configuration for SGD optimization
#
run.optim.fn=sgd
run.optim.conf.learningRate=0.001       # learning rate
run.optim.conf.learningRateDecay=0      # learning rate decay, as implemented by optim (1/t decay formula)
run.optim.conf.momentum=0               # momentum
run.optim.conf.weightDecay=0            # weight decay
run.optim.conf.dampening=0              # dampening for momentum
run.optim.conf.nesterov=false           # enables Nesterov momentum
